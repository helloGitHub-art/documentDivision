import cv2
import numpy as np
import os
import torch
import time

from segment_anything import SamAutomaticMaskGenerator, sam_model_registry


def sam_generate_mask_canny_and_annotate(
    img_path,
    sam_model_path,
    output_dir,
    model_type="vit_b",
    canny_low=50,
    canny_high=150,
    show_process=False,
    save_all=True,
):
    """
    å•å¼ å›¾ç‰‡å¤„ç†ï¼šSAMç”Ÿæˆæ©ç  â†’ Cannyè¾¹ç¼˜æ£€æµ‹ â†’ åŸå›¾æ ‡æ³¨ï¼ˆå¼ºåˆ¶GPUè¿è¡Œï¼‰
    :param img_path: å•å¼ å›¾ç‰‡ç»å¯¹è·¯å¾„
    :param sam_model_path: SAMæ¨¡å‹æƒé‡è·¯å¾„ï¼ˆ.pthï¼‰
    :param output_dir: ç»“æœä¿å­˜çš„æ ¹ç›®å½•ï¼ˆç»Ÿä¸€æŒ‡å®šï¼‰
    :param model_type: SAMæ¨¡å‹ç±»å‹ï¼ˆvit_b/vit_l/vit_hï¼‰
    :param canny_low: Cannyä½é˜ˆå€¼
    :param canny_high: Cannyé«˜é˜ˆå€¼
    :param show_process: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–çª—å£ï¼ˆæ‰¹é‡å¤„ç†å»ºè®®å…³é—­ï¼‰
    :param save_all: æ˜¯å¦ä¿å­˜æ‰€æœ‰ç»“æœå›¾ï¼ˆå«æ©ç ï¼‰
    :return: (å¤„ç†æˆåŠŸæ ‡å¿—, å¤„ç†è€—æ—¶ç§’æ•°)
    """
    start_time = time.time()
    try:
        if not torch.cuda.is_available():
            raise RuntimeError("æœªæ£€æµ‹åˆ°CUDA GPUï¼è¯·ç¡®è®¤æ˜¾å¡é©±åŠ¨/å®‰è£…CUDAç‰ˆæœ¬/PyTorchæ˜¯å¦æ”¯æŒGPU")

        device = torch.device("cuda:0")
        torch.cuda.set_device(device)

        img = cv2.imread(img_path)
        if img is None:
            print(f"âš ï¸ è·³è¿‡ï¼šæœªæ‰¾åˆ°å›¾ç‰‡ {img_path}")
            return False, time.time() - start_time

        img_original = img.copy()
        h_ori, w_ori = img_original.shape[:2]

        scale = 800 / max(h_ori, w_ori)
        img_resize = cv2.resize(img, (int(w_ori * scale), int(h_ori * scale)))
        img_rgb = cv2.cvtColor(img_resize, cv2.COLOR_BGR2RGB)

        os.makedirs(output_dir, exist_ok=True)
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        save_path_mask = os.path.join(output_dir, f"{img_name}_sam_mask.png")
        save_path_canny = os.path.join(output_dir, f"{img_name}_sam_canny.png")
        save_path_annotated = os.path.join(output_dir, f"{img_name}_sam_annotated.png")

        torch.cuda.empty_cache()
        sam = sam_model_registry[model_type](checkpoint=sam_model_path)
        sam.to(device=device)
        sam.eval()

        mask_generator = SamAutomaticMaskGenerator(
            model=sam,
            points_per_side=32,
            pred_iou_thresh=0.9,
            stability_score_thresh=0.9,
            crop_n_layers=1,
            crop_n_points_downscale_factor=2,
            min_mask_region_area=1000,
            output_mode="binary_mask",
        )

        masks = mask_generator.generate(img_rgb)
        if not masks:
            print(f"âš ï¸ è·³è¿‡ï¼š{img_path} SAMæœªç”Ÿæˆä»»ä½•æ©ç ")
            return False, time.time() - start_time

        masks = sorted(masks, key=lambda x: x["area"], reverse=True)
        best_mask = masks[0]["segmentation"]
        mask_binary = (best_mask.astype(np.uint8)) * 255

        mask_blurred = cv2.GaussianBlur(mask_binary, (5, 5), 0)
        canny_edges = cv2.Canny(mask_blurred, canny_low, canny_high)
        kernel = np.ones((3, 3), np.uint8)
        canny_edges = cv2.morphologyEx(canny_edges, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(
            canny_edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        if not contours:
            print(f"âš ï¸ è·³è¿‡ï¼š{img_path} ä»Cannyè¾¹ç¼˜å›¾æœªæå–åˆ°è½®å»“")
            return False, time.time() - start_time

        max_contour = max(contours, key=cv2.contourArea)

        perimeter = cv2.arcLength(max_contour, True)
        doc_corners = None
        for epsilon_ratio in [0.02, 0.015, 0.025, 0.01, 0.03, 0.04]:
            approx = cv2.approxPolyDP(max_contour, epsilon_ratio * perimeter, True)
            if len(approx) == 4:
                doc_corners = approx.reshape(4, 2)
                break

        if doc_corners is None:
            print(f"âš ï¸ {img_path}ï¼šæœªæ‹Ÿåˆå‡º4ä¸ªé¡¶ç‚¹ï¼Œä½¿ç”¨å‡¸åŒ…è¿‘ä¼¼")
            hull = cv2.convexHull(max_contour)
            hull_perimeter = cv2.arcLength(hull, True)
            for epsilon_ratio in [0.02, 0.03, 0.04]:
                approx = cv2.approxPolyDP(hull, epsilon_ratio * hull_perimeter, True)
                if len(approx) == 4:
                    doc_corners = approx.reshape(4, 2)
                    break

        if doc_corners is None:
            print(f"âš ï¸ {img_path}ï¼šå‡¸åŒ…è¿‘ä¼¼å¤±è´¥ï¼Œä½¿ç”¨è½®å»“æå€¼ç‚¹")
            leftmost = tuple(max_contour[max_contour[:, :, 0].argmin()][0])
            rightmost = tuple(max_contour[max_contour[:, :, 0].argmax()][0])
            topmost = tuple(max_contour[max_contour[:, :, 1].argmin()][0])
            bottommost = tuple(max_contour[max_contour[:, :, 1].argmax()][0])
            doc_corners = np.array(
                [leftmost, rightmost, bottommost, topmost], dtype=np.int32
            )

        doc_corners_ori = (doc_corners / scale).astype(np.int32)
        img_annotated = img_original.copy()
        cv2.drawContours(img_annotated, [doc_corners_ori], -1, (0, 255, 0), 2)
        for i, (x, y) in enumerate(doc_corners_ori):
            cv2.circle(img_annotated, (x, y), 6, (0, 0, 255), -1)
            cv2.putText(
                img_annotated,
                f"({x},{y})",
                (x - 30, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 0, 0),
                1,
            )

        if save_all:
            cv2.imwrite(save_path_mask, mask_binary)
            cv2.imwrite(save_path_canny, canny_edges)
            cv2.imwrite(save_path_annotated, img_annotated)
            elapsed_time = time.time() - start_time
            print(f"âœ… å·²å¤„ç†ï¼š{img_name} â†’ ç»“æœä¿å­˜è‡³ {output_dir} | è€—æ—¶ï¼š{elapsed_time:.2f} ç§’")

        if show_process:
            cv2.imshow("1-SAMæ©ç ï¼ˆä¿ç•™ï¼‰", mask_binary)
            cv2.imshow("2-Cannyè¾¹ç¼˜", canny_edges)
            cv2.imshow("3-æ ‡æ³¨åçš„åŸå›¾", img_annotated)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        torch.cuda.empty_cache()
        elapsed_time = time.time() - start_time
        return True, elapsed_time

    except Exception as e:
        elapsed_time = time.time() - start_time
        print(f"âŒ å¤„ç†å¤±è´¥ï¼š{os.path.basename(img_path)} â†’ {str(e)} | è€—æ—¶ï¼š{elapsed_time:.2f} ç§’")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        return False, elapsed_time


def batch_process_images(
    input_dir,
    output_dir,
    sam_model_path,
    model_type="vit_b",
    canny_low=50,
    canny_high=150,
    show_process=False,
    save_all=True,
):
    """
    æ‰¹é‡å¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
    :param input_dir: è¾“å…¥å›¾ç‰‡ç›®å½•
    :param output_dir: è¾“å‡ºç»“æœç›®å½•
    :param sam_model_path: SAMæ¨¡å‹æƒé‡è·¯å¾„
    :param model_type: SAMæ¨¡å‹ç±»å‹
    """
    batch_start_time = time.time()

    if not os.path.exists(input_dir):
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨ï¼š{input_dir}")

    supported_formats = (".png", ".jpg", ".jpeg", ".bmp", ".tiff", ".tif")
    img_files = [
        os.path.join(input_dir, f)
        for f in os.listdir(input_dir)
        if f.lower().endswith(supported_formats)
    ]

    if not img_files:
        print(f"âš ï¸ è¾“å…¥ç›®å½• {input_dir} ä¸‹æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")
        return

    total = len(img_files)
    success_count = 0
    total_elapsed_time = 0.0
    print(f"\nğŸ“Œ å¼€å§‹æ‰¹é‡å¤„ç†ï¼šå…± {total} å¼ å›¾ç‰‡")
    print(f"ğŸ“Œ è¾“å…¥ç›®å½•ï¼š{input_dir}")
    print(f"ğŸ“Œ è¾“å‡ºç›®å½•ï¼š{output_dir}\n")

    for idx, img_path in enumerate(img_files, 1):
        print(f"[{idx}/{total}] æ­£åœ¨å¤„ç†ï¼š{os.path.basename(img_path)}")
        success, elapsed = sam_generate_mask_canny_and_annotate(
            img_path=img_path,
            sam_model_path=sam_model_path,
            output_dir=output_dir,
            model_type=model_type,
            canny_low=canny_low,
            canny_high=canny_high,
            show_process=show_process,
            save_all=save_all,
        )
        if success:
            success_count += 1
        total_elapsed_time += elapsed

    batch_total_time = time.time() - batch_start_time
    avg_time_per_img = total_elapsed_time / total if total > 0 else 0

    print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"âœ… æˆåŠŸï¼š{success_count} å¼ ")
    print(f"âŒ å¤±è´¥ï¼š{total - success_count} å¼ ")
    print(f"â±ï¸  å•å¼ å¹³å‡è€—æ—¶ï¼š{avg_time_per_img:.2f} ç§’/å¼ ")
    print(f"â±ï¸  æ‰¹é‡æ€»è€—æ—¶ï¼š{batch_total_time:.2f} ç§’")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³ï¼š{output_dir}")
